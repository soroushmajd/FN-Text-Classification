{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea45b9a5-d5d8-45d8-b9b7-b4a2c1adf711",
        "id": "wq_FkxYWgIXl"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Jy8XF9fNNNp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/WELFake_Dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1P9HFU1JNjzu"
      },
      "outputs": [],
      "source": [
        "df=df.dropna()\n",
        "df=df.reset_index()\n",
        "df=df[[\"text\",'label']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLU8tigVQara"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "def clean_text(article):\n",
        "    #print(article)\n",
        "    text = article.lower()\n",
        "    text = text.replace('\\n', \" \")\n",
        "    tokens = text.split(\" \")\n",
        "    regex = \"[a-zA-Z]\"\n",
        "    refined_tokens = []\n",
        "    for item in tokens:\n",
        "        if re.match(regex, item):\n",
        "            refined_tokens.append(item)\n",
        "    cleaned_text = ' '.join(token for token in refined_tokens)\n",
        "    return cleaned_text.translate(str.maketrans('', '', string.punctuation))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYP4kDnyQeqx"
      },
      "outputs": [],
      "source": [
        "\n",
        "df['cleaned_text'] = df['text'].apply(lambda x: clean_text(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AA_CuwPQnLY",
        "outputId": "11bc6233-4248-4e55-a1ca-3ae358d08800"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(71537, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df=df[[\"cleaned_text\",\"label\"]]\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.loc[0:10000, :]"
      ],
      "metadata": {
        "id": "L4ZVQF1tW3Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "qbDisKDnRYCE",
        "outputId": "95fe5ec3-9205-444d-863a-f918f828fd92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Number of label ')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.countplot(df.label)\n",
        "plt.xlabel('Label')\n",
        "plt.title('Number of label ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uxo9pClfQWbG"
      },
      "outputs": [],
      "source": [
        "df.to_csv('/content/drive/MyDrive/cleaned_data1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thglP80GXrYC"
      },
      "outputs": [],
      "source": [
        "dff=pd.read_csv('/content/drive/MyDrive/cleaned_data1.csv',lineterminator=\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oR38JLAZC7g"
      },
      "outputs": [],
      "source": [
        "df=dff[[\"cleaned_text\",\"label\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZwby-SOSKpy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01ddb64f-b2e4-427a-8bb4-8d24a179a4bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "finish loading library\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fcb45185650>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "import torch\n",
        "!pip install transformers\n",
        "import transformers as ppb\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "gpu_available = False\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    gpu_available = True\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "print(\"finish loading library\")\n",
        "\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9XJUDlhdagy"
      },
      "outputs": [],
      "source": [
        "df=dff.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c450zry8dD2W"
      },
      "outputs": [],
      "source": [
        "df = df.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7wCdvracLI0"
      },
      "outputs": [],
      "source": [
        "df=df[[\"cleaned_text\",\"label\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "o_FNZbqjb7oV",
        "outputId": "a44dd1e3-af6b-43c7-c877-4ded3f6cafb5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        cleaned_text  label\n",
              "0  no comment is expected from barack obama membe...      1\n",
              "1  now most of the demonstrators gathered last ni...      1\n",
              "2  a dozen politically active pastors came here f...      0\n",
              "3  the rs28 sarmat missile dubbed satan will repl...      1\n",
              "4  all we can say on this one is it s about time ...      1\n",
              "5  dr ben carson tells the story of what happened...      1\n",
              "6  the owner of the ringling bar located south of...      1\n",
              "7  file in this sept file photo the marker that w...      1\n",
              "8  the most punchable altright nazi on the intern...      1\n",
              "9  brussels british prime minister theresa may s ...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e6f4af0-76ca-4fb4-820b-fd8d292e5891\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>no comment is expected from barack obama membe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>now most of the demonstrators gathered last ni...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a dozen politically active pastors came here f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the rs28 sarmat missile dubbed satan will repl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>all we can say on this one is it s about time ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>dr ben carson tells the story of what happened...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>the owner of the ringling bar located south of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>file in this sept file photo the marker that w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>the most punchable altright nazi on the intern...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>brussels british prime minister theresa may s ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e6f4af0-76ca-4fb4-820b-fd8d292e5891')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0e6f4af0-76ca-4fb4-820b-fd8d292e5891 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0e6f4af0-76ca-4fb4-820b-fd8d292e5891');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(df, test_size=0.2)"
      ],
      "metadata": {
        "id": "0gHdM6Z5Rt4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=train[[\"cleaned_text\",\"label\"]]"
      ],
      "metadata": {
        "id": "XRBye9f8SBbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.reset_index()\n",
        "test=test[[\"cleaned_text\",\"label\"]]"
      ],
      "metadata": {
        "id": "NFeXnFjGSJXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_csv('/content/drive/MyDrive/train.csv')\n",
        "test.to_csv('/content/drive/MyDrive/test.csv')\n"
      ],
      "metadata": {
        "id": "2_NSNcKzScx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17qR6NjAx4yz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ba9df6b-f168-474b-c529-d31f0f898f4f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "from sklearn import metrics\n",
        "\n",
        "#Load training and test data\n",
        "#Change the path if needed\n",
        "training_data = pd.read_csv(\"/content/drive/MyDrive/train.csv\", index_col = 0,lineterminator=\"\\n\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/test.csv\", index_col = 0,lineterminator=\"\\n\")\n",
        "\n",
        "training_label = training_data[\"label\"].values\n",
        "training_content = training_data[\"cleaned_text\"].values.astype(\"str\")\n",
        "\n",
        "\n",
        "test_label = test_data[\"label\"].values\n",
        "test_content = test_data[\"cleaned_text\"].values.astype(\"str\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"finish loading data\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finish loading data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WY7cKdGZe3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caec56e7-b065-4b1b-d372-d0012295859b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "#Tokenization\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, AdamW, get_linear_schedule_with_warmup, BertForMultipleChoice\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case = True)\n",
        "training_input_ids = []\n",
        "training_attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in training_data['cleaned_text']:\n",
        "    \n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 128,       \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   \n",
        "                        return_tensors = 'pt',    \n",
        "                        # return_overflowing_tokens = False\n",
        "                   )\n",
        "    \n",
        "    training_input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    training_attention_masks.append(encoded_dict['attention_mask'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4nePe8IZm9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac21f9c9-88fa-46b6-835d-32c87c6f5e30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "\n",
        "training_input_ids = torch.cat(training_input_ids, dim=0)\n",
        "training_attention_masks = torch.cat(training_attention_masks, dim=0)\n",
        "training_labels = torch.tensor(training_label, dtype = torch.long)   \n",
        "\n",
        "\n",
        "\n",
        "test_input_ids = []\n",
        "test_attention_masks = []\n",
        "\n",
        "\n",
        "for sent in test_data['cleaned_text']:\n",
        "    encoded = tokenizer.encode_plus(\n",
        "                        sent,                      \n",
        "                        add_special_tokens = True, \n",
        "                        max_length = 128,          \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   \n",
        "                        return_tensors = 'pt',     \n",
        "                   )\n",
        "    test_input_ids.append(encoded['input_ids'])\n",
        "    test_attention_masks.append(encoded['attention_mask'])\n",
        "\n",
        "validation_inputs = torch.cat(test_input_ids, dim=0)\n",
        "validation_masks = torch.cat(test_attention_masks, dim=0)\n",
        "validation_labels = torch.tensor(test_label, dtype = torch.long)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J75yzz8AeVTh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf92338a-5da4-417b-beeb-1dcf339facbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finish tokenization\n"
          ]
        }
      ],
      "source": [
        "\n",
        "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
        "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
        "test_labels = torch.tensor(test_label, dtype = torch.long)\n",
        "\n",
        "\n",
        "              \n",
        "print(\"finish tokenization\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYxZMVE8euH7"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Generate Dataset\n",
        "\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "train_dataset = TensorDataset(training_input_ids, training_attention_masks, training_labels)\n",
        "val_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
        "\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "\n",
        "batch_size = 8 #16\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset, \n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset), \n",
        "            batch_size = len(test_data) \n",
        "        )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRjDKO7ffGAx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05f78f33-b1d8-4a1b-bce3-57fb572303d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, AdamW, get_linear_schedule_with_warmup, BertForMultipleChoice\n",
        "\n",
        "\n",
        "\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels = 2, output_attentions = False, output_hidden_states = False)\n",
        "\n",
        "                    \n",
        "\n",
        "\n",
        "model.cuda()\n",
        "\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr = 3e-5, eps =1e-8)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcklzj_qfIxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c37ce339-04bf-4d10-9274-dd79edb7dba4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch   100  of    989.    Elapsed: 0:00:23.\n",
            "  Batch   200  of    989.    Elapsed: 0:00:43.\n",
            "  Batch   300  of    989.    Elapsed: 0:01:04.\n",
            "  Batch   400  of    989.    Elapsed: 0:01:25.\n",
            "  Batch   500  of    989.    Elapsed: 0:01:46.\n",
            "  Batch   600  of    989.    Elapsed: 0:02:08.\n",
            "  Batch   700  of    989.    Elapsed: 0:02:30.\n",
            "  Batch   800  of    989.    Elapsed: 0:02:51.\n",
            "  Batch   900  of    989.    Elapsed: 0:03:13.\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epcoh took: 0:03:32\n",
            "\n",
            "Running Validation...\n",
            "[[992   3]\n",
            " [ 93 889]]\n",
            "  Accuracy: 0.95144\n",
            "  Precision: 0.99664\n",
            "  Recall: 0.90530\n",
            "  f1-score: 0.94877\n",
            "  Validation Loss: 0.27\n",
            "  Validation took: 0:00:15\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch   100  of    989.    Elapsed: 0:00:22.\n",
            "  Batch   200  of    989.    Elapsed: 0:00:43.\n",
            "  Batch   300  of    989.    Elapsed: 0:01:05.\n",
            "  Batch   400  of    989.    Elapsed: 0:01:27.\n",
            "  Batch   500  of    989.    Elapsed: 0:01:49.\n",
            "  Batch   600  of    989.    Elapsed: 0:02:10.\n",
            "  Batch   700  of    989.    Elapsed: 0:02:32.\n",
            "  Batch   800  of    989.    Elapsed: 0:02:54.\n",
            "  Batch   900  of    989.    Elapsed: 0:03:16.\n",
            "\n",
            "  Average training loss: 0.11\n",
            "  Training epcoh took: 0:03:35\n",
            "\n",
            "Running Validation...\n",
            "[[990   5]\n",
            " [ 85 897]]\n",
            "  Accuracy: 0.95448\n",
            "  Precision: 0.99446\n",
            "  Recall: 0.91344\n",
            "  f1-score: 0.95223\n",
            "  Validation Loss: 0.26\n",
            "  Validation took: 0:00:14\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch   100  of    989.    Elapsed: 0:00:22.\n",
            "  Batch   200  of    989.    Elapsed: 0:00:44.\n",
            "  Batch   300  of    989.    Elapsed: 0:01:05.\n",
            "  Batch   400  of    989.    Elapsed: 0:01:27.\n",
            "  Batch   500  of    989.    Elapsed: 0:01:49.\n",
            "  Batch   600  of    989.    Elapsed: 0:02:11.\n",
            "  Batch   700  of    989.    Elapsed: 0:02:32.\n",
            "  Batch   800  of    989.    Elapsed: 0:02:54.\n",
            "  Batch   900  of    989.    Elapsed: 0:03:16.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:03:35\n",
            "\n",
            "Running Validation...\n",
            "[[975  20]\n",
            " [ 43 939]]\n",
            "  Accuracy: 0.96813\n",
            "  Precision: 0.97914\n",
            "  Recall: 0.95621\n",
            "  f1-score: 0.96754\n",
            "  Validation Loss: 0.20\n",
            "  Validation took: 0:00:14\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:11:31 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, \n",
        "                                            num_training_steps = total_steps)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "def flat_score(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    print(confusion_matrix(labels_flat, pred_flat))\n",
        "    score = precision_recall_fscore_support(labels_flat, pred_flat, average = None)\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat), score[0][1], score[1][1], score[2][1]\n",
        "\n",
        "\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "\n",
        "total_t0 = time.time()\n",
        "\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "\n",
        "        if step % 100 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "  \n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "\n",
        "        model.zero_grad()  \n",
        "        outputs = model(b_input_ids,\n",
        "                    token_type_ids=None,\n",
        "                    attention_mask=b_input_mask,\n",
        "                    labels=b_labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "    \n",
        "    torch.save(model.state_dict(),'bert' + str(epoch_i) + '.pt')\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "  \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "    precision = 0\n",
        "    recall = 0\n",
        "    f1_score = 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "\n",
        "        with torch.no_grad():        \n",
        "\n",
        "\n",
        "            outputs = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        total_eval_loss += loss.item()\n",
        "        logits = outputs[1]\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "\n",
        "        scores = flat_score(logits, label_ids)\n",
        "        total_eval_accuracy += scores[0]\n",
        "        precision += scores[1]\n",
        "        recall += scores[2]\n",
        "        f1_score += scores[3]\n",
        "        \n",
        "\n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.5f}\".format(avg_val_accuracy))\n",
        "    print(\"  Precision: {0:.5f}\".format(precision))\n",
        "    print(\"  Recall: {0:.5f}\".format(recall))\n",
        "    print(\"  f1-score: {0:.5f}\".format(f1_score))\n",
        "\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "RoBERTa",
      "provenance": [],
      "toc_visible": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}